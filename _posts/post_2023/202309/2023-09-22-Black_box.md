---
layout: post
title: ML 알고리즘 분석을 위한 eXplainable Method 
tags: [ML]
categories: [ML]
sitemap:
  changefreq: daily
  priority : 1.0
---

머신러닝(ML)에 입문과정이라고 볼 수 있는 eXpainable Method에 대해서 학습한 내용을 정리했다.  

----

목차
- toc
{: toc }

----  

### Black Box  

ML 알고리즘은 내부 구조가 복잡해질 수록 모델 내부에 어떻게 작동하는지 확인하기가 어렵다. 이를 여객기나, 수송기에 사용되는 Black Box의 표현을 사용하고 있다.  

예를 들어 결정트리는 단순하게 트리 구조로 되어 있어서 사람이 모델에서 결정한 분리조건을 도시화할 수 있다. 하지만 랜덤포레스트와 같이 모델이 앙상블 구조로 되어 있거나 CNN, RNN 처럼 아주 복잡한 구조로 구성되어 있다면 모델이 왜? 이런 output이 나왔는지 확인하기가 어렵다.(거의 불가능에 가까운)   

![성능과 설명가능성](/assets/img/my_photo/ML_0011.png)  


### LIME(Local Model-Agnostic Methods) 설명  

+ Local : 특정 Y  
+ Interpretable : 해석 가능한  
+ Model-agnostic : Model Free(Model에 상관없이 적용가능)  
+ Explanation : 설명이 가능하다  
+ etc : 숫자, 텍스트, 이미지 등 모든 데이터에 적용 가능하다. 

아래 그림과 같이 특정 피처의 일부 범위에 해당하는 값을 input하여 output의 값을 보고 국소적으로 어떤 판단으로 결과값이 도출되는지 유추해볼 수 있다.  

![예시1](/assets/img/my_photo/ML_0012.png)  


모델을 분석하는 순서는 

모델 구축 및 데이터 셋에 대한 예측까지는 일반적인 순서이고, 이 다음부터는 모델을 설명하기 위한 순서이다. 분석자가 판단하여 특정 피처들을 선별하고 분석하고자 하는 데이터의 범위(range, 수치가 높은 집단 또는 낮은 집단)를 결정하여 결과값에 대해서 설명하고 분석자가 최종적으로 판단한다.  

1. 모델 구축  
2. 데이터 셋 및 예측  
3. 특정 데이터 결정(pick step)  
        + 확실한 Pattern이 있는 데이터를 추출하기 위해서 (학습이 잘된 데이터) MSE가 낮은 데이터를 추출한다.  
4. 설명  
        + pick step에서 추출한 중요인자를 도출  
        + 도출은 LIME를 활용  
5. 분석자 판단  

![그림2](/assets/img/my_photo/ML_0013.png)  


### SHAP  

SHAP는 LIME 개념 + 경제학 개념으로 게임이론(Shapley Values)을 접목시켰다.  

실습 코드를 살펴보면 내가 캐글에 올린 데이터로 분석해준 그래프가 존재하는데 그게 SHAP인 것을 확인했다. 공부할 필요성이 상당히 높다.  

실습 코드 : [SHAP 코드 링크](https://github.com/sooyoung-wind/sooyoung-wind.github.io/blob/main/ipynb/ML_Basic_Course/Chap03.06.SHAP%20Code%20%EC%8B%A4%EC%8A%B5.ipynb)  


