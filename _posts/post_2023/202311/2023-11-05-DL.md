---
layout: post
title: DL_Q&A   
tags: [DL]
categories: [DL]
sitemap:
  changefreq: daily
  priority : 1.0
---

Q1. Augmentation에서 A.Resize -> A.RandomCrop -> A.HorizontalFlip -> A.Normalize -> TotensorV2 순으로 작성한대로 실행되는 순서인가요? 이 내부에서 돌아가는 구조로를 이해못하고 있고 어느 만큼 데이터가 증강되는지 이해 못하고 있습니다.

> 순서대로 실행되는 것은 맞다. Augmentation은 내부에서 데이터를 조작해서 훈련을 시킨다. 여기서 p 값을 사용해서 전체 데이터의 갯수에서 몇 개를 조작하는지 그 비율을 의미한다. 

Q2. train_one_epoch의 함수를 만들어서 이걸 epoch마다 실행하는 구조로 만든걸로 이해했습니다.  이렇게 한 이유가 코드를 관리하기 위해서라고 생각되는데요.(1기능 1함수 측면에서)
이거 말고 다른 이유가 있으면 설명 부탁드립니다.
> 질문 그 자체로 코드를 용이하게 사용하기 위해서함


Q3. train_one_epoch에서 "with torch.autocast(device_type='cuda', dtype=torch.float16):" 구문이 있습니다. 이 부분에 대해서 설명 부탁드립니다. ---> cpu로 할려고 하니 이걸 생략해야 실행이 되었는데요. 뭔지 파악은 못했습니다.
> GPU에서는 float16으로 해도 성능에 문제가 없고 계산도 빨라진다. 그래서 거의 default로 사용한다.
> mixed precision 개념이라고 한다. cpu는 float32로 해야 동작된다.

Q4. pretrained 모델을 가져다가 사용했는데요. 여기서 훈련을 한다면 기존 모델의 가중치들을 업데이트 하는 것인가요? 기존 모델을 그냥 놔둔채 뒤쪽에 추가 모델을 구성해서 추가모델만 훈련 시킬 수 있나요?
> timm 기능에 freeze라는 기능이 있어서 이걸 사용하면 pretrained model에서 학습된 모델은 학습하지 않고 뒤에 붙은 신규 모델만 훈련하게 할 수 있다.

Q5. timm으로 모델을 불러오는 것과 hf를 통헤 모델을 이용하는 것은 다른가요?
> 같은 의미임

Q6. 데이터 증강을 개수가 부족한 클래스에만 적용하는 것은 어떤가요?
> 까먹음 --> 근데 이렇게 해도 문제가 없어서 되는 느낌이였다.
