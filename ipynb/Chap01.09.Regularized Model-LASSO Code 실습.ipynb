{"cells":[{"cell_type":"markdown","metadata":{"id":"z_8amITGuz9p"},"source":["# **<font color=white> 09.Regularized Model-LASSO Code 실습**\n","\n","[목적]\n","  1. LASSO\n","    - Regularized Linear Model을 활용하여 Overfitting을 방지함\n","    - Hyperparameter lamba를 튜닝할 때 for loop 뿐만 아니라 GridsearchCV를 통해 돌출해봄\n","  3. Regularized Linear Models의 경우 X's Scaling을 필수적으로 진행해야함\n","\n","[Process]\n","  1. Define X's & Y\n","  2. Split Train & Valid dataset\n","  3. Modeling\n","  4. Model 해석"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2201,"status":"ok","timestamp":1677291468026,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"eEav2vLmvDUW"},"outputs":[],"source":["# Package\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import Lasso, LassoCV\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Sklearn Toy Data\n","from sklearn.datasets import load_diabetes"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1041,"status":"ok","timestamp":1677291474067,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"xj_6LXKfvHfe"},"outputs":[],"source":["# Data Loading (당뇨병)\n","data = pd.read_csv('https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt', sep='\\t')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":274,"status":"ok","timestamp":1677291482548,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"XEQN5_pFvPfb"},"outputs":[],"source":["# X's & Y Split\n","Y = data['Y']\n","X = data.drop(columns=['Y']) \n","X = pd.get_dummies(X, columns=['SEX'])"]},{"cell_type":"markdown","metadata":{"id":"OO20YmpavlyT"},"source":["[Data Split]\n","\n","- Data Split을 진행할 때 BigData의 경우 꼭 indexing을 추출하여 모델에 적용시켜야 함\n","- 이유는 Data Split하여 새로운 Data set을 만들 경우 메모리에 부담을 주기 때문"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":299,"status":"ok","timestamp":1677291586248,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"fIzJ0HvrvnHQ","outputId":"852a6af4-96c1-4a21-a10e-1998a6158fac"},"outputs":[{"name":"stdout","output_type":"stream","text":[">>>> # of Train data : 309\n",">>>> # of valid data : 133\n"]}],"source":["idx = list(range(X.shape[0]))\n","train_idx, valid_idx = train_test_split(idx, test_size=0.3, random_state=2023)\n","print(\">>>> # of Train data : {}\".format(len(train_idx)))\n","print(\">>>> # of valid data : {}\".format(len(valid_idx)))"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":294,"status":"ok","timestamp":1677291588074,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"QJ0-iBZIvtcV"},"outputs":[],"source":["# Scaling\n","scaler = MinMaxScaler().fit(X.iloc[train_idx])\n","X_scal = scaler.transform(X)\n","X_scal = pd.DataFrame(X_scal, columns=X.columns)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":284,"status":"ok","timestamp":1677291597053,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"J278N1pix6v0"},"outputs":[],"source":["import scipy\n","from sklearn import metrics\n","\n","def sse(clf, X, y):\n","    \"\"\"Calculate the standard squared error of the model.\n","    Parameters\n","    ----------\n","    clf : sklearn.linear_model\n","        A scikit-learn linear model classifier with a `predict()` method.\n","    X : numpy.ndarray\n","        Training data used to fit the classifier.\n","    y : numpy.ndarray\n","        Target training values, of shape = [n_samples].\n","    Returns\n","    -------\n","    float\n","        The standard squared error of the model.\n","    \"\"\"\n","    y_hat = clf.predict(X)\n","    sse = np.sum((y_hat - y) ** 2)\n","    return sse / X.shape[0]\n","\n","\n","def adj_r2_score(clf, X, y):\n","    \"\"\"Calculate the adjusted :math:`R^2` of the model.\n","    Parameters\n","    ----------\n","    clf : sklearn.linear_model\n","        A scikit-learn linear model classifier with a `predict()` method.\n","    X : numpy.ndarray\n","        Training data used to fit the classifier.\n","    y : numpy.ndarray\n","        Target training values, of shape = [n_samples].\n","    Returns\n","    -------\n","    float\n","        The adjusted :math:`R^2` of the model.\n","    \"\"\"\n","    n = X.shape[0]  # Number of observations\n","    p = X.shape[1]  # Number of features\n","    r_squared = metrics.r2_score(y, clf.predict(X))\n","    return 1 - (1 - r_squared) * ((n - 1) / (n - p - 1))\n","\n","\n","def coef_se(clf, X, y):\n","    \"\"\"Calculate standard error for beta coefficients.\n","    Parameters\n","    ----------\n","    clf : sklearn.linear_model\n","        A scikit-learn linear model classifier with a `predict()` method.\n","    X : numpy.ndarray\n","        Training data used to fit the classifier.\n","    y : numpy.ndarray\n","        Target training values, of shape = [n_samples].\n","    Returns\n","    -------\n","    numpy.ndarray\n","        An array of standard errors for the beta coefficients.\n","    \"\"\"\n","    n = X.shape[0]\n","    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n","    se_matrix = scipy.linalg.sqrtm(\n","        metrics.mean_squared_error(y, clf.predict(X)) *\n","        np.linalg.inv(X1.T * X1)\n","    )\n","    return np.diagonal(se_matrix)\n","\n","\n","def coef_tval(clf, X, y):\n","    \"\"\"Calculate t-statistic for beta coefficients.\n","    Parameters\n","    ----------\n","    clf : sklearn.linear_model\n","        A scikit-learn linear model classifier with a `predict()` method.\n","    X : numpy.ndarray\n","        Training data used to fit the classifier.\n","    y : numpy.ndarray\n","        Target training values, of shape = [n_samples].\n","    Returns\n","    -------\n","    numpy.ndarray\n","        An array of t-statistic values.\n","    \"\"\"\n","    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n","    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n","    return np.append(a, b)\n","\n","\n","def coef_pval(clf, X, y):\n","    \"\"\"Calculate p-values for beta coefficients.\n","    Parameters\n","    ----------\n","    clf : sklearn.linear_model\n","        A scikit-learn linear model classifier with a `predict()` method.\n","    X : numpy.ndarray\n","        Training data used to fit the classifier.\n","    y : numpy.ndarray\n","        Target training values, of shape = [n_samples].\n","    Returns\n","    -------\n","    numpy.ndarray\n","        An array of p-values.\n","    \"\"\"\n","    n = X.shape[0]\n","    t = coef_tval(clf, X, y)\n","    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n","    return p\n","\n","def summary(clf, X, y, xlabels=None):\n","    \"\"\"\n","    Output summary statistics for a fitted regression model.\n","    Parameters\n","    ----------\n","    clf : sklearn.linear_model\n","        A scikit-learn linear model classifier with a `predict()` method.\n","    X : numpy.ndarray\n","        Training data used to fit the classifier.\n","    y : numpy.ndarray\n","        Target training values, of shape = [n_samples].\n","    xlabels : list, tuple\n","        The labels for the predictors.\n","    \"\"\"\n","    # Check and/or make xlabels\n","    ncols = X.shape[1]\n","    if xlabels is None:\n","        xlabels = np.array(\n","            ['x{0}'.format(i) for i in range(1, ncols + 1)], dtype='str')\n","    elif isinstance(xlabels, (tuple, list)):\n","        xlabels = np.array(xlabels, dtype='str')\n","    # Make sure dims of xlabels matches dims of X\n","    if xlabels.shape[0] != ncols:\n","        raise AssertionError(\n","            \"Dimension of xlabels {0} does not match \"\n","            \"X {1}.\".format(xlabels.shape, X.shape))\n","    # Create data frame of coefficient estimates and associated stats\n","    coef_df = pd.DataFrame(\n","        index=['_intercept'] + list(xlabels),\n","        columns=['Estimate', 'Std. Error', 't value', 'p value']\n","    )\n","    try:\n","        coef_df['Estimate'] = np.concatenate(\n","            (np.round(np.array([clf.intercept_]), 6), np.round((clf.coef_), 6)))\n","    except Exception as e:\n","        coef_df['Estimate'] = np.concatenate(\n","            (\n","                np.round(np.array([clf.intercept_]), 6),\n","                np.round((clf.coef_), 6)\n","            ), axis = 1\n","    )[0,:]\n","    coef_df['Std. Error'] = np.round(coef_se(clf, X, y), 6)\n","    coef_df['t value'] = np.round(coef_tval(clf, X, y), 4)\n","    coef_df['p value'] = np.round(coef_pval(clf, X, y), 6)\n","    # Output results\n","    print('Coefficients:')\n","    print(coef_df.to_string(index=True))\n","    print('---')\n","    print('R-squared:  {0:.6f},    Adjusted R-squared:  {1:.6f},    MSE: {2:.1f}'.format(\n","        metrics.r2_score(y, clf.predict(X)), adj_r2_score(clf, X, y), sse(clf, X, y)))"]},{"cell_type":"markdown","metadata":{"id":"NpbuDO_QwS1V"},"source":["[LASSO Regression]\n","\n","  - Hyperparameter Tuning using for Loop\n","  - Hyperparameter Tuning using GridSearchCV"]},{"cell_type":"markdown","metadata":{"id":"qlOHHjGDw6f_"},"source":["[LASSO Regression Parameters]\n","  - Package : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n","  - alpha : L1-norm Penalty Term\n","    - alpha : 0 일 때, Just Linear Regression  \n","  - fit_intercept : Centering to zero\n","    - 베타0를 0로 보내는 것 (베타0는 상수이기 때문에)\n","  - max_iter : Maximum number of interation\n","    - Loss Function의 LASSO Penalty Term은 절대 값이기 때문에 Gradient Descent와 같은 최적화가 필요함\n","    - Penalty Term : ||y - Xw||^2_2 + alpha * ||w||_1"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269,"status":"ok","timestamp":1677292060233,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"oChNUa87x3Qw","outputId":"008d1aed-cb67-45d6-c0f0-ba9cfeeb0268"},"outputs":[{"name":"stdout","output_type":"stream","text":["Alpha:0.0000001, R2:0.5301651, MSE:3084.6122329, RMSE:55.5392855\n","Alpha:0.0000005, R2:0.5301651, MSE:3084.6121132, RMSE:55.5392844\n","Alpha:0.0000010, R2:0.5301652, MSE:3084.6119624, RMSE:55.5392831\n","Alpha:0.0000050, R2:0.5301653, MSE:3084.6107549, RMSE:55.5392722\n","Alpha:0.0000100, R2:0.5301656, MSE:3084.6092464, RMSE:55.5392586\n","Alpha:0.0000500, R2:0.5301674, MSE:3084.5972157, RMSE:55.5391503\n","Alpha:0.0001000, R2:0.5301697, MSE:3084.5822667, RMSE:55.5390157\n","Alpha:0.0010000, R2:0.5302081, MSE:3084.3301897, RMSE:55.5367463\n","Alpha:0.0100000, R2:0.5304264, MSE:3082.8971348, RMSE:55.5238429\n","Alpha:0.0200000, R2:0.5306024, MSE:3081.7414647, RMSE:55.5134350\n","Alpha:0.0300000, R2:0.5304378, MSE:3082.8220339, RMSE:55.5231666\n"]},{"name":"stdout","output_type":"stream","text":["Alpha:0.0400000, R2:0.5300232, MSE:3085.5438451, RMSE:55.5476718\n"]}],"source":["penelty = [0.0000001, 0.0000005, 0.000001, 0.000005,0.00001, 0.00005, 0.0001, 0.001, 0.01, 0.02, 0.03, 0.04]\n","\n","# LASSO Regression\n","# select alpha by checking R2, MSE, RMSE\n","for a in penelty:\n","    model = Lasso(alpha=a).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])  \n","    score = model.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n","    pred_y = model.predict(X_scal.iloc[valid_idx])\n","    mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n","    print(\"Alpha:{0:.7f}, R2:{1:.7f}, MSE:{2:.7f}, RMSE:{3:.7f}\".format(a, score, mse, np.sqrt(mse)))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":436,"status":"ok","timestamp":1677292139215,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"o_9J-VW7yFlo","outputId":"d6356bed-8116-4100-a64a-08794cbda45e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Coefficients:\n","              Estimate    Std. Error  t value   p value\n","_intercept    4.144976  4.243796e+08   0.0000  1.000000\n","AGE         -13.359132  2.398793e+01  -0.5569  0.578532\n","BMI         127.876677  3.179278e+01   4.0222  0.000097\n","BP           66.897382  2.821704e+01   2.3708  0.019195\n","S1         -153.025383  1.637981e+02  -0.9342  0.351890\n","S2          102.155001  1.158209e+02   0.8820  0.379375\n","S3          -10.583686  7.115286e+01  -0.1487  0.881981\n","S4            9.263867  5.671769e+01   0.1633  0.870506\n","S5          181.017864  5.060787e+01   3.5769  0.000487\n","S6           18.390761  3.420233e+01   0.5377  0.591686\n","SEX_1        20.777166  4.243796e+08   0.0000  1.000000\n","SEX_2        -0.000000  4.243796e+08  -0.0000  1.000000\n","---\n","R-squared:  0.530602,    Adjusted R-squared:  0.487930,    MSE: 3081.7\n"]}],"source":["model_best = Lasso(alpha=0.02).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n","summary(model_best, X_scal.iloc[valid_idx], Y.iloc[valid_idx], xlabels=X.columns)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306,"status":"ok","timestamp":1677292308216,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"ZmRKo5URy8vR","outputId":"25b4bc65-c76d-4613-883b-c25e912c0571"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Alpha : 0.0400000\n"]}],"source":["# Cross Validation for LASSO\n","lasso_cv=LassoCV(alphas=penelty, cv=5)\n","model = lasso_cv.fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n","print(\"Best Alpha : {:.7f}\".format(model.alpha_))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1677292321215,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"atGocZWXzFfP","outputId":"5034d50c-4569-41ff-f74c-7ee61e246d30"},"outputs":[{"name":"stdout","output_type":"stream","text":["Alpha:0.0400000, R2:0.5300232, MSE:3085.5438451, RMSE:55.5476718\n","Coefficients:\n","              Estimate    Std. Error  t value   p value\n","_intercept   21.394535  4.246414e+08   0.0000  1.000000\n","AGE         -12.257581  2.390083e+01  -0.5129  0.608912\n","BMI         128.605286  3.181731e+01   4.0420  0.000090\n","BP           66.620187  2.824793e+01   2.3584  0.019821\n","S1          -76.209202  1.639064e+02  -0.4650  0.642729\n","S2           42.479334  1.159924e+02   0.3662  0.714783\n","S3          -43.437386  7.118132e+01  -0.6102  0.542755\n","S4            2.391818  5.686693e+01   0.0421  0.966514\n","S5          154.680886  5.049057e+01   3.0636  0.002652\n","S6           17.493148  3.424450e+01   0.5108  0.610323\n","SEX_1        20.663264  4.246414e+08   0.0000  1.000000\n","SEX_2        -0.000000  4.246414e+08  -0.0000  1.000000\n","---\n","R-squared:  0.530023,    Adjusted R-squared:  0.487298,    MSE: 3085.5\n"]}],"source":["model_best = Lasso(alpha=model.alpha_).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n","score = model_best.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n","pred_y = model_best.predict(X_scal.iloc[valid_idx])\n","mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n","print(\"Alpha:{0:.7f}, R2:{1:.7f}, MSE:{2:.7f}, RMSE:{3:.7f}\".format(model.alpha_, score, mse, np.sqrt(mse)))\n","summary(model_best, X_scal.iloc[valid_idx], Y.iloc[valid_idx], xlabels=X.columns)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPLjWbVr/bA+wyJQx8hV4p9","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
