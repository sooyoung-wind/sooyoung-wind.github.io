{"cells":[{"cell_type":"markdown","metadata":{"id":"_tnaIxWwz12s"},"source":["# **<font color=white> 11.Regularized Model-ElasticNet Code 실습**\n","\n","[목적]\n","  1. ElasticNet\n","    - Regularized Linear Model을 활용하여 Overfitting을 방지함\n","    - Hyperparameter lamba를 튜닝할 때 for loop 뿐만 아니라 GridsearchCV를 통해 돌출해봄\n","  3. Regularized Linear Models의 경우 X's Scaling을 필수적으로 진행해야함\n","\n","[Process]\n","  1. Define X's & Y\n","  2. Split Train & Valid dataset\n","  3. Modeling\n","  4. Model 해석"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2946,"status":"ok","timestamp":1677292698846,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"oiQ-XJ2R0OHh"},"outputs":[],"source":["# Package\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import ElasticNet, ElasticNetCV\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Sklearn Toy Data\n","from sklearn.datasets import load_diabetes"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1677292698847,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"xBgwUFGN0dwJ"},"outputs":[],"source":["# Data Loading (당뇨병)\n","data = pd.read_csv('https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt', sep='\\t')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1677292698848,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"Lm1a8GFy0hPK"},"outputs":[],"source":["# X's & Y Split\n","Y = data['Y']\n","X = data.drop(columns=['Y']) \n","X = pd.get_dummies(X, columns=['SEX'])"]},{"cell_type":"markdown","metadata":{"id":"X0cmlQUH0jk2"},"source":["[Data Split]\n","\n","- Data Split을 진행할 때 BigData의 경우 꼭 indexing을 추출하여 모델에 적용시켜야 함\n","- 이유는 Data Split하여 새로운 Data set을 만들 경우 메모리에 부담을 주기 때문"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":319,"status":"ok","timestamp":1677292705397,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"e3qj8GOQ0l2Z","outputId":"8e18bc48-3233-4e78-c321-6f890aabe777"},"outputs":[{"name":"stdout","output_type":"stream","text":[">>>> # of Train data : 309\n",">>>> # of valid data : 133\n"]}],"source":["idx = list(range(X.shape[0]))\n","train_idx, valid_idx = train_test_split(idx, test_size=0.3, random_state=2023)\n","print(\">>>> # of Train data : {}\".format(len(train_idx)))\n","print(\">>>> # of valid data : {}\".format(len(valid_idx)))"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":274,"status":"ok","timestamp":1677292748444,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"y_zV-_h90nFD"},"outputs":[],"source":["# Scaling\n","scaler = MinMaxScaler().fit(X.iloc[train_idx])\n","X_scal = scaler.transform(X)\n","X_scal = pd.DataFrame(X_scal, columns=X.columns)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":383,"status":"ok","timestamp":1677292751701,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"TY3jqRwK0oyj"},"outputs":[],"source":["import scipy\n","from sklearn import metrics\n","\n","def sse(clf, X, y):\n","    \"\"\"Calculate the standard squared error of the model.\n","    Parameters\n","    ----------\n","    clf : sklearn.linear_model\n","        A scikit-learn linear model classifier with a `predict()` method.\n","    X : numpy.ndarray\n","        Training data used to fit the classifier.\n","    y : numpy.ndarray\n","        Target training values, of shape = [n_samples].\n","    Returns\n","    -------\n","    float\n","        The standard squared error of the model.\n","    \"\"\"\n","    y_hat = clf.predict(X)\n","    sse = np.sum((y_hat - y) ** 2)\n","    return sse / X.shape[0]\n","\n","\n","def adj_r2_score(clf, X, y):\n","    \"\"\"Calculate the adjusted :math:`R^2` of the model.\n","    Parameters\n","    ----------\n","    clf : sklearn.linear_model\n","        A scikit-learn linear model classifier with a `predict()` method.\n","    X : numpy.ndarray\n","        Training data used to fit the classifier.\n","    y : numpy.ndarray\n","        Target training values, of shape = [n_samples].\n","    Returns\n","    -------\n","    float\n","        The adjusted :math:`R^2` of the model.\n","    \"\"\"\n","    n = X.shape[0]  # Number of observations\n","    p = X.shape[1]  # Number of features\n","    r_squared = metrics.r2_score(y, clf.predict(X))\n","    return 1 - (1 - r_squared) * ((n - 1) / (n - p - 1))\n","\n","\n","def coef_se(clf, X, y):\n","    \"\"\"Calculate standard error for beta coefficients.\n","    Parameters\n","    ----------\n","    clf : sklearn.linear_model\n","        A scikit-learn linear model classifier with a `predict()` method.\n","    X : numpy.ndarray\n","        Training data used to fit the classifier.\n","    y : numpy.ndarray\n","        Target training values, of shape = [n_samples].\n","    Returns\n","    -------\n","    numpy.ndarray\n","        An array of standard errors for the beta coefficients.\n","    \"\"\"\n","    n = X.shape[0]\n","    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n","    se_matrix = scipy.linalg.sqrtm(\n","        metrics.mean_squared_error(y, clf.predict(X)) *\n","        np.linalg.inv(X1.T * X1)\n","    )\n","    return np.diagonal(se_matrix)\n","\n","\n","def coef_tval(clf, X, y):\n","    \"\"\"Calculate t-statistic for beta coefficients.\n","    Parameters\n","    ----------\n","    clf : sklearn.linear_model\n","        A scikit-learn linear model classifier with a `predict()` method.\n","    X : numpy.ndarray\n","        Training data used to fit the classifier.\n","    y : numpy.ndarray\n","        Target training values, of shape = [n_samples].\n","    Returns\n","    -------\n","    numpy.ndarray\n","        An array of t-statistic values.\n","    \"\"\"\n","    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n","    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n","    return np.append(a, b)\n","\n","\n","def coef_pval(clf, X, y):\n","    \"\"\"Calculate p-values for beta coefficients.\n","    Parameters\n","    ----------\n","    clf : sklearn.linear_model\n","        A scikit-learn linear model classifier with a `predict()` method.\n","    X : numpy.ndarray\n","        Training data used to fit the classifier.\n","    y : numpy.ndarray\n","        Target training values, of shape = [n_samples].\n","    Returns\n","    -------\n","    numpy.ndarray\n","        An array of p-values.\n","    \"\"\"\n","    n = X.shape[0]\n","    t = coef_tval(clf, X, y)\n","    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n","    return p\n","\n","def summary(clf, X, y, xlabels=None):\n","    \"\"\"\n","    Output summary statistics for a fitted regression model.\n","    Parameters\n","    ----------\n","    clf : sklearn.linear_model\n","        A scikit-learn linear model classifier with a `predict()` method.\n","    X : numpy.ndarray\n","        Training data used to fit the classifier.\n","    y : numpy.ndarray\n","        Target training values, of shape = [n_samples].\n","    xlabels : list, tuple\n","        The labels for the predictors.\n","    \"\"\"\n","    # Check and/or make xlabels\n","    ncols = X.shape[1]\n","    if xlabels is None:\n","        xlabels = np.array(\n","            ['x{0}'.format(i) for i in range(1, ncols + 1)], dtype='str')\n","    elif isinstance(xlabels, (tuple, list)):\n","        xlabels = np.array(xlabels, dtype='str')\n","    # Make sure dims of xlabels matches dims of X\n","    if xlabels.shape[0] != ncols:\n","        raise AssertionError(\n","            \"Dimension of xlabels {0} does not match \"\n","            \"X {1}.\".format(xlabels.shape, X.shape))\n","    # Create data frame of coefficient estimates and associated stats\n","    coef_df = pd.DataFrame(\n","        index=['_intercept'] + list(xlabels),\n","        columns=['Estimate', 'Std. Error', 't value', 'p value']\n","    )\n","    try:\n","        coef_df['Estimate'] = np.concatenate(\n","            (np.round(np.array([clf.intercept_]), 6), np.round((clf.coef_), 6)))\n","    except Exception as e:\n","        coef_df['Estimate'] = np.concatenate(\n","            (\n","                np.round(np.array([clf.intercept_]), 6),\n","                np.round((clf.coef_), 6)\n","            ), axis = 1\n","    )[0,:]\n","    coef_df['Std. Error'] = np.round(coef_se(clf, X, y), 6)\n","    coef_df['t value'] = np.round(coef_tval(clf, X, y), 4)\n","    coef_df['p value'] = np.round(coef_pval(clf, X, y), 6)\n","    # Output results\n","    print('Coefficients:')\n","    print(coef_df.to_string(index=True))\n","    print('---')\n","    print('R-squared:  {0:.6f},    Adjusted R-squared:  {1:.6f},    MSE: {2:.1f}'.format(\n","        metrics.r2_score(y, clf.predict(X)), adj_r2_score(clf, X, y), sse(clf, X, y)))"]},{"cell_type":"markdown","metadata":{"id":"wbAG61wz0sao"},"source":["[ElasticNet Regression]\n","\n","  - Hyperparameter Tuning using for Loop\n","  - Hyperparameter Tuning using GridSearchCV"]},{"cell_type":"markdown","metadata":{"id":"WvPCwCrC06AK"},"source":["[ElasticNet Regression Parameters]\n","  - Package : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n","  - alpha : L2-norm Penalty Term\n","    - alpha : 0 일 때, Just Linear Regression\n","  - l1_ratio : L1-norm Penalty Term\n","    - 0 <= l1_ratio <= 1\n","    - l1_ratio : 1 일 때, Just Ridge Regression\n","  - fit_intercept : Centering to zero\n","    - 베타0를 0로 보내는 것 (베타0는 상수이기 때문에)\n","  - max_iter : Maximum number of interation\n","    - Loss Function의 LASSO Penalty Term은 절대 값이기 때문에 Gradient Descent와 같은 최적화가 필요함\n","  - Penalty Term \n","    - 1 / (2 * n_samples) * ||y - Xw||^2_2 + <u>alpha * l1_ratio * ||w||_1</u> + <u>0.5 * alpha * (1 - l1_ratio) * ||w||^2_2</u>"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":953,"status":"ok","timestamp":1677293271060,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"YvHXUA8D0r5L","outputId":"f7923300-9134-4e3e-fdc7-e9d14e8b885e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Alpha:0.0000010, l1_ratio: 0.9000000, R2:0.5301664, MSE:3084.6036665, RMSE:55.5392084\n","Alpha:0.0000010, l1_ratio: 0.7000000, R2:0.5301689, MSE:3084.5871229, RMSE:55.5390594\n","Alpha:0.0000010, l1_ratio: 0.5000000, R2:0.5301714, MSE:3084.5706467, RMSE:55.5389111\n","Alpha:0.0000010, l1_ratio: 0.3000000, R2:0.5301739, MSE:3084.5542376, RMSE:55.5387634\n","Alpha:0.0000010, l1_ratio: 0.1000000, R2:0.5301764, MSE:3084.5378953, RMSE:55.5386163\n","Alpha:0.0000050, l1_ratio: 0.9000000, R2:0.5301716, MSE:3084.5694666, RMSE:55.5389005\n","Alpha:0.0000050, l1_ratio: 0.7000000, R2:0.5301840, MSE:3084.4881189, RMSE:55.5381681\n"]},{"name":"stdout","output_type":"stream","text":["Alpha:0.0000050, l1_ratio: 0.5000000, R2:0.5301962, MSE:3084.4084152, RMSE:55.5374506\n","Alpha:0.0000050, l1_ratio: 0.3000000, R2:0.5302081, MSE:3084.3303231, RMSE:55.5367475\n","Alpha:0.0000050, l1_ratio: 0.1000000, R2:0.5302197, MSE:3084.2538107, RMSE:55.5360587\n","Alpha:0.0000100, l1_ratio: 0.9000000, R2:0.5301781, MSE:3084.5271311, RMSE:55.5385193\n","Alpha:0.0000100, l1_ratio: 0.7000000, R2:0.5302023, MSE:3084.3677950, RMSE:55.5370849\n","Alpha:0.0000100, l1_ratio: 0.5000000, R2:0.5302256, MSE:3084.2148395, RMSE:55.5357078\n","Alpha:0.0000100, l1_ratio: 0.3000000, R2:0.5302480, MSE:3084.0680163, RMSE:55.5343859\n","Alpha:0.0000100, l1_ratio: 0.1000000, R2:0.5302695, MSE:3083.9270883, RMSE:55.5331170\n","Alpha:0.0000500, l1_ratio: 0.9000000, R2:0.5302272, MSE:3084.2044920, RMSE:55.5356146\n","Alpha:0.0000500, l1_ratio: 0.7000000, R2:0.5303300, MSE:3083.5299323, RMSE:55.5295411\n","Alpha:0.0000500, l1_ratio: 0.5000000, R2:0.5304135, MSE:3082.9815630, RMSE:55.5246032\n","Alpha:0.0000500, l1_ratio: 0.3000000, R2:0.5304811, MSE:3082.5375315, RMSE:55.5206046\n","Alpha:0.0000500, l1_ratio: 0.1000000, R2:0.5305356, MSE:3082.1801728, RMSE:55.5173862\n","Alpha:0.0001000, l1_ratio: 0.9000000, R2:0.5302829, MSE:3083.8388547, RMSE:55.5323226\n","Alpha:0.0001000, l1_ratio: 0.7000000, R2:0.5304499, MSE:3082.7427965, RMSE:55.5224531\n","Alpha:0.0001000, l1_ratio: 0.5000000, R2:0.5305586, MSE:3082.0291476, RMSE:55.5160260\n","Alpha:0.0001000, l1_ratio: 0.3000000, R2:0.5306274, MSE:3081.5773111, RMSE:55.5119565\n","Alpha:0.0001000, l1_ratio: 0.1000000, R2:0.5306667, MSE:3081.3192662, RMSE:55.5096322\n","Alpha:0.0010000, l1_ratio: 0.9000000, R2:0.5306800, MSE:3081.2315891, RMSE:55.5088424\n","Alpha:0.0010000, l1_ratio: 0.7000000, R2:0.5304790, MSE:3082.5518032, RMSE:55.5207331\n","Alpha:0.0010000, l1_ratio: 0.5000000, R2:0.5301610, MSE:3084.6392459, RMSE:55.5395287\n","Alpha:0.0010000, l1_ratio: 0.3000000, R2:0.5298684, MSE:3086.5602166, RMSE:55.5568197\n","Alpha:0.0010000, l1_ratio: 0.1000000, R2:0.5295913, MSE:3088.3797285, RMSE:55.5731925\n","Alpha:0.0050000, l1_ratio: 0.9000000, R2:0.5300847, MSE:3085.1400812, RMSE:55.5440373\n","Alpha:0.0050000, l1_ratio: 0.7000000, R2:0.5286871, MSE:3094.3158567, RMSE:55.6265751\n","Alpha:0.0050000, l1_ratio: 0.5000000, R2:0.5270274, MSE:3105.2121269, RMSE:55.7244303\n","Alpha:0.0050000, l1_ratio: 0.3000000, R2:0.5251678, MSE:3117.4212399, RMSE:55.8338718\n","Alpha:0.0050000, l1_ratio: 0.1000000, R2:0.5231038, MSE:3130.9721621, RMSE:55.9550906\n","Alpha:0.0100000, l1_ratio: 0.9000000, R2:0.5292941, MSE:3090.3309148, RMSE:55.5907449\n","Alpha:0.0100000, l1_ratio: 0.7000000, R2:0.5259488, MSE:3112.2937214, RMSE:55.7879353\n","Alpha:0.0100000, l1_ratio: 0.5000000, R2:0.5218304, MSE:3139.3320523, RMSE:56.0297426\n","Alpha:0.0100000, l1_ratio: 0.3000000, R2:0.5171797, MSE:3169.8655476, RMSE:56.3015590\n","Alpha:0.0100000, l1_ratio: 0.1000000, R2:0.5122265, MSE:3202.3849382, RMSE:56.5896186\n","Alpha:0.0500000, l1_ratio: 0.9000000, R2:0.5202820, MSE:3149.4981176, RMSE:56.1203895\n","Alpha:0.0500000, l1_ratio: 0.7000000, R2:0.4947158, MSE:3317.3479797, RMSE:57.5964233\n","Alpha:0.0500000, l1_ratio: 0.5000000, R2:0.4684468, MSE:3489.8124002, RMSE:59.0746342\n","Alpha:0.0500000, l1_ratio: 0.3000000, R2:0.4441825, MSE:3649.1148990, RMSE:60.4079043\n","Alpha:0.0500000, l1_ratio: 0.1000000, R2:0.4217886, MSE:3796.1375164, RMSE:61.6128032\n"]}],"source":["# alphas, alpha = 0 is equivalent to an ordinary least square, solved by the LinearRegression object.\n","alphas = [0.000001, 0.000005, 0.00001, 0.00005, 0.0001, 0.001, 0.005, 0.01, 0.05]\n","# betas range (0 ~ 1), l1_ratio is often to put more values close to 1 (i.e. Lasso) and less close to 0 (i.e. Ridge)\n","l1_ratio = [0.9, 0.7, 0.5, 0.3, 0.1]\n","\n","# ElasticNet Regression\n","# select alpha and beta by checking R2, MSE, RMSE\n","for a in alphas:\n","    for b in l1_ratio:\n","        model = ElasticNet(alpha=a, l1_ratio=b).fit(X_scal.iloc[train_idx], Y.iloc[train_idx]) \n","        score = model.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n","        pred_y = model.predict(X_scal.iloc[valid_idx])\n","        mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n","        print(\"Alpha:{0:.7f}, l1_ratio: {1:.7f}, R2:{2:.7f}, MSE:{3:.7f}, RMSE:{4:.7f}\".format(a, b, score, mse, np.sqrt(mse)))"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1677293382842,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"AcX2zjc80qd9"},"outputs":[],"source":["# Cross Validation for ElasticNet\n","grid = dict()\n","grid['alpha'] = alphas\n","grid['l1_ratio'] = l1_ratio"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1677293393789,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"Awp7MVF8efRs","outputId":"fef428d1-5813-407d-ecb5-e5472235b60e"},"outputs":[{"data":{"text/plain":["{'alpha': [1e-06, 5e-06, 1e-05, 5e-05, 0.0001, 0.001, 0.005, 0.01, 0.05],\n"," 'l1_ratio': [0.9, 0.7, 0.5, 0.3, 0.1]}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["grid"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2621,"status":"ok","timestamp":1677293444509,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"FzfdnkEl3UdL","outputId":"bc341011-8c28-4cff-cb65-3b0309a5111c"},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE: 56.8906\n","Config: {'alpha': 0.01, 'l1_ratio': 0.3}\n"]}],"source":["# define model\n","model = ElasticNet()\n","# define search\n","search = GridSearchCV(model, grid, scoring='neg_root_mean_squared_error', cv=5, n_jobs=-1)\n","# perform the search\n","results = search.fit(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n","# summarize\n","print('RMSE: {:.4f}'.format(-results.best_score_))\n","print('Config: {}'.format(results.best_params_))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1677293453731,"user":{"displayName":"안건이","userId":"00323974519415085515"},"user_tz":-540},"id":"O4X98Td53ei7","outputId":"8e9632e2-1e8e-4525-9512-502b84d37299"},"outputs":[{"name":"stdout","output_type":"stream","text":["Alpha:0.0100000, l1_ratio: 0.3000000, R2:0.5171797, MSE:3169.8655476, RMSE:56.3015590\n","Coefficients:\n","              Estimate                  Std. Error         t value   p value\n","_intercept   45.921027  4.304046e+08+3.161352e+00j  0.0000-0.0000j  1.000000\n","AGE          -7.326230  2.347123e+01+7.634200e-01j -0.3118+0.0101j  0.755554\n","BMI         112.053983  3.218924e+01+1.973670e-01j  3.4810-0.0213j  0.000678\n","BP           63.835355  2.838353e+01+5.208310e-01j  2.2483-0.0413j  0.026192\n","S1          -10.286770  1.660045e+02+4.273140e-01j -0.0620+0.0002j  0.950683\n","S2          -11.664902  1.172206e+02+7.303950e-01j -0.0995+0.0006j  0.920884\n","S3          -51.885195  7.175728e+01+9.207300e-02j -0.7231+0.0009j  0.470919\n","S4           26.375923  5.750615e+01+3.575170e-01j  0.4586-0.0029j  0.647237\n","S5          102.402575  5.126996e+01-9.916700e-02j  1.9973+0.0039j  0.047847\n","S6           25.791145  3.427508e+01+6.024560e-01j  0.7522-0.0132j  0.453175\n","SEX_1        10.231459  4.304046e+08+5.375030e-01j  0.0000-0.0000j  1.000000\n","SEX_2        -9.855686  4.304046e+08+2.970800e-02j -0.0000+0.0000j  1.000000\n","---\n","R-squared:  0.517180,    Adjusted R-squared:  0.473287,    MSE: 3169.9\n"]}],"source":["model_best = ElasticNet(alpha=results.best_params_['alpha'], \n","                        l1_ratio=results.best_params_['l1_ratio']).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n","score = model_best.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n","pred_y = model_best.predict(X_scal.iloc[valid_idx])\n","mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n","print(\"Alpha:{0:.7f}, l1_ratio: {1:.7f}, R2:{2:.7f}, MSE:{3:.7f}, RMSE:{4:.7f}\".format(results.best_params_['alpha'], \n","                                                                                   results.best_params_['l1_ratio'], \n","                                                                                   score, mse, np.sqrt(mse)))\n","summary(model_best, X_scal.iloc[valid_idx], Y.iloc[valid_idx], xlabels=X.columns)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOT0E7fxLzK0a7lJ3Dv3VDE","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
